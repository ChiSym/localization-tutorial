{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "integrate_controls (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "using JSON: parsefile\n",
    "using WGLMakie\n",
    "using Gen\n",
    "using StaticArrays\n",
    "using Printf\n",
    "\n",
    "norm(v) = sqrt(sum(v.^2))\n",
    "import Base.angle\n",
    "\n",
    "struct Pose\n",
    "    position::SVector{2,Float64}\n",
    "    angle::Float64\n",
    "    orientation::SVector{2,Float64} \n",
    "end\n",
    "\n",
    "position(pose::Pose) = pose.position\n",
    "angle(pose::Pose) = pose.angle\n",
    "orientation(pose::Pose) = pose.orientation\n",
    "Pose(position, angle::Float64) = Pose(position, rem2pi(angle, RoundNearest), SVector(cos(angle), sin(angle)))\n",
    "Pose(position, orientation::AbstractVector{Float64}) = Pose(position, atan(orientation[2], orientation[1]))\n",
    "Base.show(io::IO, p::Pose) = print(io, \"Pose(\", p.position, \" \", p.angle, \")\")\n",
    "\n",
    "struct Control\n",
    "    ds ::Float64\n",
    "    dhd::Float64\n",
    "end\n",
    "\n",
    "step_along_pose(pose::Pose, step_size::Float64) = position(pose) .+ step_size .* orientation(pose)\n",
    "rotate_pose(pose::Pose, Δθ::Float64) = Pose(position(pose), angle(pose) + Δθ)\n",
    "\n",
    "function integrate_controls_unphysical(start_pose::Pose, robot_inputs::Vector{Control})\n",
    "    path = Vector{Pose}(undef, length(robot_inputs.controls) + 1)\n",
    "    path[1] = start_pose\n",
    "    for t in 1:length(robot_inputs)\n",
    "        position_new = step_along_pose(path[t], robot_inputs[t])\n",
    "        angle_new = path[t].hd + robot_inputs[t].dhd\n",
    "        path[t+1] = Pose(position_new, angle_new)\n",
    "    end\n",
    "    return path\n",
    "end\n",
    "\n",
    "# %% [markdown]\n",
    "# This code has the problem that it is **unphysical**: the walls in no way constrain the robot motion.\n",
    "#\n",
    "# We employ the following simple physics: when the robot's forward step through a control comes into contact with a wall, that step is interrupted and the robot instead \"bounces\" a fixed distance from the point of contact in the normal direction to the wall.\n",
    "\n",
    "# %%\n",
    "# Return unique s, t such that p + s*u == q + t*v.\n",
    "function solve_lines(p, u, q, v; PARALLEL_TOL=1.0e-10)\n",
    "    det = u[1] * v[2] - u[2] * v[1]\n",
    "    if abs(det) < PARALLEL_TOL\n",
    "        return nothing, nothing\n",
    "    else\n",
    "        s = (v[1] * (p[2]-q[2]) - v[2] * (p[1]-q[1])) / det\n",
    "        t = (u[2] * (q[1]-p[1]) - u[1] * (q[2]-p[2])) / det\n",
    "        return s, t\n",
    "    end\n",
    "end\n",
    "\n",
    "function distance(pose, segment)\n",
    "    s, t = solve_lines(position(pose), orientation(pose), segment.p1, segment.dp)\n",
    "    # Solving failed (including, by fiat, if pose is parallel to segment) iff isnothing(s).\n",
    "    # Pose is oriented away from segment iff s < 0.\n",
    "    # Point of intersection lies on segment (as opposed to the infinite line) iff 0 <= t <= 1.\n",
    "    return (isnothing(s) || s < 0. || !(0. <= t <= 1.)) ? Inf : s\n",
    "end\n",
    "\n",
    "function physical_step(p1, p2, hd, world_inputs)\n",
    "    step_pose = Pose(p1, p2 .- p1)\n",
    "    (s, i) = findmin(w -> distance(step_pose, w), world_inputs.walls)\n",
    "    if s > norm(p2 .- p1)\n",
    "        # Step succeeds without contact with walls.\n",
    "        return Pose(p2, hd)\n",
    "    else\n",
    "        dp = orientation(step_pose)\n",
    "        contact_point = p1 .+ s .* dp\n",
    "        unit_tangent = world_inputs.walls[i].dp / norm(world_inputs.walls[i].dp)\n",
    "        unit_normal = SVector(-unit_tangent[2], unit_tangent[1])\n",
    "        # Sign of 2D cross product determines orientation of bounce.\n",
    "        if dp[1] * world_inputs.walls[i].dp[2] - dp[2] * world_inputs.walls[i].dp[1] < 0.\n",
    "            unit_normal = -unit_normal\n",
    "        end\n",
    "        return Pose(contact_point + world_inputs.bounce * unit_normal, hd)\n",
    "    end\n",
    "end\n",
    "\n",
    "function integrate_controls(robot_init::Pose, robot_inputs::Vector{Control}, world_inputs)\n",
    "    path = Vector{Pose}(undef, length(robot_inputs) + 1)\n",
    "    path[1] = robot_init\n",
    "    for t in 1:length(robot_inputs)\n",
    "        position_new = step_along_pose(path[t], robot_inputs[t].dhd)\n",
    "        angle_new = angle(path[t]) + robot_inputs[t].dhd\n",
    "        # Perform the physical correction\n",
    "        path[t+1] = physical_step(position(path[t]), position_new, angle_new, world_inputs)\n",
    "    end\n",
    "    return path\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "load_world (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "include(\"world.jl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "const World = @NamedTuple{walls::Vector{Segment}, clutters::Vector{Vector{Segment}}, walls_clutters::Vector{Segment}, bounding_box::NTuple{4, Float64}, box_size::Float64, center_point::Vector{Float64}}\n",
    "const SensorSettings = @NamedTuple{fov::Float64, sensor_count::Int64, box_size::Float64, s_noise::Float64}\n",
    "\n",
    "WGLMakie.@recipe(WorldMap) do scene\n",
    "    WGLMakie.Attributes(\n",
    "        labelworld = false,\n",
    "        upcolor = :green,\n",
    "    )\n",
    "end\n",
    "\n",
    "function WGLMakie.plot!(wm::WorldMap{<:Tuple{World}})\n",
    "    world = wm[1]\n",
    "    # labelworld = wm.labelworld\n",
    "    walls = world[].walls\n",
    "    for w in walls\n",
    "        WGLMakie.lines!(wm, stack([first(w), last(w)]), color=:black)\n",
    "    end\n",
    "    wm\n",
    "end\n",
    "\n",
    "function WGLMakie.convert_arguments(::Type{<:WGLMakie.Arrows}, poses::Vector{Pose})\n",
    "    x = WGLMakie.Point2f.(position.(poses))\n",
    "    theta = WGLMakie.Point2f.(orientation.(poses))\n",
    "    return (x,theta)\n",
    "end\n",
    "\n",
    "function WGLMakie.convert_arguments(::Type{<:WGLMakie.Arrows}, pose::Pose)\n",
    "    x = WGLMakie.Point2f(position(pose))\n",
    "    theta = WGLMakie.Point2f(orientation(pose))\n",
    "    return ([x], [theta])\n",
    "end\n",
    "\n",
    "function WGLMakie.convert_arguments(::Type{<:WGLMakie.Scatter}, pose::Pose)\n",
    "    return (WGLMakie.Point2f(position(pose)),)\n",
    "end\n",
    "\n",
    "function WGLMakie.convert_arguments(::Type{<:WGLMakie.LineSegments}, pose::Pose, sensor_settings::SensorSettings, readings::AbstractVector{Float64})\n",
    "    x = position(pose)\n",
    "    projections = [step_along_pose(rotate_pose(pose, sensor_angle(sensor_settings, j)), s) for (j, s) in enumerate(readings)]\n",
    "    return ([1],[1])\n",
    "end\n",
    "\n",
    "function plot_sensors!(pose, color, readings, label, sensor_settings)\n",
    "    plot!([position(pose)[1]], [position(pose)[2]]; color=color, label=nothing, seriestype=:scatter, markersize=3, markerstrokewidth=0)\n",
    "    projections = [step_along_pose(rotate_pose(pose, sensor_angle(sensor_settings, j)), s) for (j, s) in enumerate(readings)]\n",
    "    plot!(first.(projections), last.(projections);\n",
    "            color=:blue, label=label, seriestype=:scatter, markersize=3, markerstrokewidth=1, alpha=0.25)\n",
    "    plot!([Segment(position(pose), pr) for pr in projections]; color=:blue, label=nothing, alpha=0.25)\n",
    "end\n",
    "\n",
    "function frame_from_sensors(world, title, poses, poses_color, poses_label, pose, readings, readings_label, sensor_settings; show_clutters=false)\n",
    "    the_plot = plot_world(world, title; show_clutters=show_clutters)\n",
    "    plot!(poses; color=poses_color, label=poses_label)\n",
    "    plot_sensors!(pose, poses_color, readings, readings_label, sensor_settings)\n",
    "    return the_plot\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20-element Vector{Pose}:\n",
       " Pose([1.8437380952380948, 16.669857142857147] 0.08090409915523009)\n",
       " Pose([1.2180983085992596, 16.619129592589132] -0.5467888408892483)\n",
       " Pose([1.2632405428236255, 16.591651710887344] -0.49394136891957907)\n",
       " Pose([1.6981416432133127, 16.357474195292898] 0.0)\n",
       " Pose([1.0402530380311035, 16.357474195292898] -0.6578886051822093)\n",
       " Pose([0.46019822709756464, 16.805698367377904] -1.390942827002419)\n",
       " Pose([0.4280250549753868, 16.982650814049883] -1.5707963267948966)\n",
       " Pose([0.4280250549753868, 16.771557480827138] -1.3597029935721499)\n",
       " Pose([0.4577566155201923, 16.632810198284712] -1.2178059389679858)\n",
       " Pose([0.7422772489355456, 15.860539907585897] -0.3947911196997622)\n",
       " Pose([0.8271137886199686, 15.825191349384054] -0.30288486837497053)\n",
       " Pose([1.082137242847622, 15.745496519937912] -0.03569911267932424)\n",
       " Pose([1.0793955135004187, 15.74559443884317] -0.038442590021188286)\n",
       " Pose([1.1178097011608614, 15.744116970087] -1.3877787807814457e-17)\n",
       " Pose([1.3152052610107436, 15.744116970087] 0.19739555984988227)\n",
       " Pose([2.468373241600131, 15.974750566204879] 1.373400766945017)\n",
       " Pose([2.4632583285818095, 15.949176001113269] 1.3473197256542642)\n",
       " Pose([2.375325083968904, 15.562269724816485] 0.9505468408120697)\n",
       " Pose([2.4064331081355643, 15.605820958649808] 1.0040671092713964)\n",
       " Pose([2.4064331081355643, 15.605820958649808] 1.0040671092713964)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "world, robot_init, robot_inputs, T = load_world(\"../example_20_program.json\");\n",
    "\n",
    "world_inputs = (walls = world.walls, bounce = 0.1)\n",
    "\n",
    "path_integrated = integrate_controls(robot_init, robot_inputs, world_inputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "WGLMakie.activate!(inline=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"bonito-fragment\" id=\"508a9aa0-52b4-480d-a509-44a863731a6b\" data-jscall-id=\"root\">\n",
       "  <div>\n",
       "    <script src=\"http://localhost:9384/assets/4a09a19ef09a5ebd335e9021db888f0a31e7ed3c-Bonito.bundled.js\" type=\"module\"></script>\n",
       "    <style></style>\n",
       "    <div></div>\n",
       "  </div>\n",
       "  <div>\n",
       "    <script type=\"module\">    Bonito.lock_loading(() => {\n",
       "        return Bonito.fetch_binary('http://localhost:9384/assets/f80f34b39fc28f87449f71eafc49f84c0c2ca481-697622564574023564.bin').then(msgs=> Bonito.init_session('508a9aa0-52b4-480d-a509-44a863731a6b', msgs, 'root'));\n",
       "    })\n",
       "</script>\n",
       "    <script type=\"module\">    import('http://localhost:9384/assets/9af6a7ab555f3e745030daedbf654713c0fe1844-Websocket.bundled.js').then(WS => {\n",
       "        WS.setup_connection({proxy_url: 'http://localhost:9384', session_id: '508a9aa0-52b4-480d-a509-44a863731a6b', compression_enabled: false})\n",
       "    })\n",
       "</script>\n",
       "    <div style=\"width: 100%; height: 100%\" data-jscall-id=\"1\">\n",
       "      <canvas style=\"display: block\" data-jscall-id=\"2\" tabindex=\"0\"></canvas>\n",
       "    </div>\n",
       "  </div>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# %% [markdown]\n",
    "# Following this initial display of the given data, we *suppress the clutters* until much later in the notebook.\n",
    "\n",
    "f = Figure()\n",
    "ax = Axis(f[1,1], aspect=DataAspect(), title=\"Start Pose Prior\")\n",
    "worldmap!(f[1,1], world)\n",
    "gridbottom = GridLayout(f[2,1])\n",
    "sl_steps = Makie.Slider(gridbottom[1,2], range=1:20)\n",
    "N_particles = sl_steps.value\n",
    "n_particle_tex = lift(N->\"# steps $(N[])\", N_particles)\n",
    "Label(gridbottom[1,1], n_particle_tex)\n",
    "displayed_path = lift((N,path)->path[1:N], N_particles, path_integrated) \n",
    "arrows!(f[1,1], displayed_path)\n",
    "f\n",
    "\n",
    "# %% [markdown]\n",
    "# We can also visualize the behavior of the model of physical motion:\n",
    "#\n",
    "# ![](imgs_stable/physical_motion.gif)\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Gen basics\n",
    "#\n",
    "# %% [markdown]\n",
    "# ### Components of the motion model\n",
    "#\n",
    "# We start with the two building blocks: the starting pose and individual steps of motion.\n",
    "\n",
    "# %%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"bonito-fragment\" id=\"1882eca0-3f57-4cae-beb4-aeddde183733\" data-jscall-id=\"root\">\n",
       "  <div>\n",
       "    <script src=\"http://localhost:9384/assets/4a09a19ef09a5ebd335e9021db888f0a31e7ed3c-Bonito.bundled.js\" type=\"module\"></script>\n",
       "    <style></style>\n",
       "    <div></div>\n",
       "  </div>\n",
       "  <div>\n",
       "    <script type=\"module\">    Bonito.lock_loading(() => {\n",
       "        return Bonito.fetch_binary('http://localhost:9384/assets/d19f996369c7b10a3815e6aad6d83cd36f34e103-8735419552780112537.bin').then(msgs=> Bonito.init_session('1882eca0-3f57-4cae-beb4-aeddde183733', msgs, 'root'));\n",
       "    })\n",
       "</script>\n",
       "    <script type=\"module\">    import('http://localhost:9384/assets/9af6a7ab555f3e745030daedbf654713c0fe1844-Websocket.bundled.js').then(WS => {\n",
       "        WS.setup_connection({proxy_url: 'http://localhost:9384', session_id: '1882eca0-3f57-4cae-beb4-aeddde183733', compression_enabled: false})\n",
       "    })\n",
       "</script>\n",
       "    <div style=\"width: 100%; height: 100%\" data-jscall-id=\"1\">\n",
       "      <canvas style=\"display: block\" data-jscall-id=\"2\" tabindex=\"0\"></canvas>\n",
       "    </div>\n",
       "  </div>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@gen (static) function start_pose_prior(start, motion_settings)\n",
    "    p ~ mvnormal(position(start), motion_settings.p_noise^2 * [1 0 ; 0 1])\n",
    "    hd ~ normal(angle(start), motion_settings.hd_noise)\n",
    "    return Pose(p, hd)\n",
    "end\n",
    "\n",
    "@gen (static) function step_model(start, control, world_inputs, motion_settings)\n",
    "    position_new = step_along_pose(start, control.ds)\n",
    "    p ~ mvnormal(position_new, motion_settings.p_noise^2 * [1 0 ; 0 1])\n",
    "    hd ~ normal(angle(start) + control.dhd, motion_settings.hd_noise)\n",
    "    return physical_step(position(start), p, hd, world_inputs)\n",
    "end\n",
    "\n",
    "# %%\n",
    "motion_settings = (p_noise = 0.5, hd_noise = 2π / 360)\n",
    "\n",
    "N_samples = 50\n",
    "pose_samples = [start_pose_prior(robot_init, motion_settings) for _ in 1:N_samples]\n",
    "\n",
    "std_devs_radius = 2.5 * motion_settings.p_noise\n",
    "\n",
    "# Map visualization\n",
    "f = Figure()\n",
    "ax = Axis(f[1,1], aspect=DataAspect(), title=\"Start Pose Prior\")\n",
    "\n",
    "worldmap!(f[1,1], world)\n",
    "\n",
    "# Sliders for motion settings\n",
    "gridbottom = GridLayout(f[2,1])\n",
    "p_noise_slider = Makie.Slider(gridbottom[1,3], range=range(0.01, 1.0, 100))\n",
    "hd_noise_slider = Makie.Slider(gridbottom[2,3], range=range(0.01, 1.0, 100))\n",
    "motion_settings = Makie.lift(p_noise_slider.value, hd_noise_slider.value) do p_noise, hd_noise\n",
    "    (p_noise = p_noise, hd_noise=hd_noise)\n",
    "end\n",
    "\n",
    "pose_samples = lift(motion_settings) do motion_settings\n",
    "    [start_pose_prior(robot_init, motion_settings) for _ in 1:20]\n",
    "end\n",
    "# Sliders for samples\n",
    "reset_n_particles_btn = Makie.Button(gridbottom[3,1], label=\"Resample\")\n",
    "n_particle_slider = Makie.Slider(gridbottom[3,3], range=1:20, startvalue=5)\n",
    "n_particles_obs = n_particle_slider.value\n",
    "\n",
    "on(reset_n_particles_btn.clicks) do n\n",
    "    reset_n_particles_btn.clicks\n",
    "    pose_samples[] = [start_pose_prior(robot_init, motion_settings[]) for _ in 1:N_samples]\n",
    "    notify(pose_samples)\n",
    "end\n",
    "\n",
    "# Numerical labels\n",
    "p_noise_tex = lift(p_noise->\"σ_p = $(p_noise[])\", p_noise_slider.value)\n",
    "hd_noise_tex = lift(hd_noise->\"σ_hd = $(hd_noise[])\", hd_noise_slider.value)\n",
    "n_particle_tex = lift(N->\"# of samples $(N[])\", n_particles_obs)\n",
    "\n",
    "Label(gridbottom[1,2], p_noise_tex)\n",
    "Label(gridbottom[2,2], hd_noise_tex)\n",
    "Label(gridbottom[3,2], n_particle_tex)\n",
    "displayed_path = lift((N,path)->path[1:N], n_particles_obs, pose_samples) \n",
    "arrows!(f[1,1], displayed_path)\n",
    "# Figure out how to get the correct units\n",
    "scatter!(f[1,1], position(robot_init)..., markersize=std_devs_radius*p_noise_slider.value[], color = Makie.RGBA(1.0, .121, .121, 0.2))\n",
    "f\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "N_samples = 50\n",
    "motion_settings = (p_noise = 0.5, hd_noise = 2π / 360)\n",
    "noiseless_step = step_along_pose(robot_init, robot_inputs[1].ds)\n",
    "step_samples = [step_model(robot_init, robot_inputs[1], world_inputs, motion_settings) for _ in 1:N_samples]\n",
    "\n",
    "# Map Visualization\n",
    "f = GLMakie.Figure()\n",
    "ax = GLMakie.Axis(f[1,1], aspect=GLMakie.DataAspect(), title=\"Motion step model (samples)\")\n",
    "worldmap!(f[1,1], world)\n",
    "\n",
    "# Sliders\n",
    "gridbottom = GLMakie.GridLayout(f[2,1])\n",
    "ds_slider = GLMakie.Slider(gridbottom[1,2], range=0:0.1:3.0, startvalue=1.6)\n",
    "dhd_slider = GLMakie.Slider(gridbottom[2,2], range=range(0, 2π, 100))\n",
    "p_noise_slider = GLMakie.Slider(gridbottom[3,2], range=range(0.01, 1.0, 100), startvalue=.3)\n",
    "hd_noise_slider = GLMakie.Slider(gridbottom[4,2], range=range(0.01, 1.0, 100), startvalue=0.3)\n",
    "n_particle_slider = GLMakie.Slider(gridbottom[5,2], range=1:20, startvalue=4)\n",
    "# reset_n_particles_btn = GLMakie.Button(f[3,1], label=\"Resample\")\n",
    "\n",
    "# Slider Text\n",
    "ds_tex = GLMakie.lift(ds->@sprintf(\"ds = %.3f\", ds[]), ds_slider.value)\n",
    "dhd_tex = GLMakie.lift(dhd->@sprintf(\"dhd = %.3f\", dhd[]), dhd_slider.value)\n",
    "p_noise_tex = GLMakie.lift(p_noise->@sprintf(\"σ_p = %.3f\", p_noise[]), p_noise_slider.value)\n",
    "hd_noise_tex = GLMakie.lift(hd_noise->@sprintf(\"σ_hd = %.3f\", hd_noise[]), hd_noise_slider.value)\n",
    "n_particle_tex = GLMakie.lift(N->\"samples = $(N[])\", n_particle_slider.value)\n",
    "\n",
    "GLMakie.Label(gridbottom[1,1], ds_tex)\n",
    "GLMakie.Label(gridbottom[2,1], dhd_tex)\n",
    "GLMakie.Label(gridbottom[3,1], p_noise_tex)\n",
    "GLMakie.Label(gridbottom[4,1], hd_noise_tex)\n",
    "GLMakie.Label(gridbottom[5,1], n_particle_tex)\n",
    "\n",
    "# Model Makie Observables\n",
    "next_control = GLMakie.lift((ds, dhd)-> Control(ds,dhd), ds_slider.value, dhd_slider.value)\n",
    "\n",
    "motion_settings = GLMakie.lift(\n",
    "    (p_noise, hd_noise)-> (p_noise = p_noise, hd_noise=hd_noise),\n",
    "    p_noise_slider.value, \n",
    "    hd_noise_slider.value\n",
    "    )\n",
    "n_particles = n_particle_slider.value\n",
    "\n",
    "step_samples = GLMakie.lift(next_control, motion_settings) do control, motion_settings\n",
    "    [step_model(robot_init, control, world_inputs, motion_settings) for _ in 1:N_samples]\n",
    "end\n",
    "\n",
    "noiseless_step = GLMakie.lift(next_control) do control\n",
    "    n = step_along_pose(robot_init, control.ds)\n",
    "    GLMakie.Point2f(n)\n",
    "end\n",
    "# GLMakie.on(reset_n_particles_btn.clicks) do n\n",
    "#     reset_n_particles_btn.clicks\n",
    "#     pose_samples[] = [start_pose_prior(robot_init, motion_settings[]) for _ in 1:N_samples]\n",
    "#     GLMakie.notify(pose_samples)\n",
    "# end\n",
    "\n",
    "\n",
    "# Visual Makie Observables\n",
    "step_samples_visible = GLMakie.lift(n_particle_slider.value, step_samples) do N, data\n",
    "    return data[1:N]\n",
    "end\n",
    "\n",
    "GLMakie.scatter!(f[1,1], noiseless_step)\n",
    "GLMakie.arrows!(f[1,1], robot_init, color=:blue)\n",
    "GLMakie.arrows!(f[1,1], step_samples_visible, color=:red)\n",
    "f\n",
    "\n",
    "# %% [markdown]\n",
    "# ### Noisy sensors\n",
    "#\n",
    "# We assume that the sensor readings are themselves uncertain, say, the distances only knowable up to some noise.  We model this as follows.  (We satisfy ourselves with writing a loop in the dynamic DSL because we will have no need for incremental recomputation within this model.)\n",
    "\n",
    "# %%\n",
    "\"\"\"\n",
    "    sensor_model(pose::Pose, walls, sensor_settings)\n",
    "\n",
    "Simulates the sensor model of the robot at `pose`, returning distance readings from the `walls` to sensors on the robot.\n",
    "\n",
    "The `sensor_settings` controls the FoV, number of sensors, range of sensors, and the reading noise.\n",
    "\"\"\"\n",
    "@gen function sensor_model(pose::Pose, walls, sensor_settings)\n",
    "    for j in 1:sensor_settings.sensor_count\n",
    "        sensor_pose = rotate_pose(pose, sensor_angle(sensor_settings, j))\n",
    "        {j => :distance} ~ normal(sensor_distance(sensor_pose, walls, sensor_settings.box_size), sensor_settings.s_noise)\n",
    "    end\n",
    "end\n",
    "\n",
    "function noisy_sensor(pose, walls, sensor_settings)\n",
    "    trace = simulate(sensor_model, (pose, walls, sensor_settings))\n",
    "    return [trace[j => :distance] for j in 1:sensor_settings.sensor_count]\n",
    "end\n",
    "\n",
    "include(\"plotting.jl\")\n",
    "\n",
    "f = GLMakie.Figure()\n",
    "ax = GLMakie.Axis(f[1,1], aspect=GLMakie.DataAspect(), title=\"Motion step model (samples)\")\n",
    "# worldmap!(f[1,1], world)\n",
    "\n",
    "\n",
    "readings = [trace[j => :distance] for j in 1:sensor_settings.sensor_count]\n",
    "GLMakie.linesegments!(f[1,1], robot_init, sensor_settings)\n",
    "frame_plot = frame_from_sensors_trace(\n",
    "    world, \"Sensor model (samples)\",\n",
    "    path_integrated, :green2, \"some path\",\n",
    "    pose, trace\n",
    "    )\n",
    "f\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# %% [markdown]\n",
    "# ### Full model\n",
    "#\n",
    "# We fold the sensor model into the motion model to form a \"full model\", whose traces describe simulations of the entire robot situation as we have described it.\n",
    "\n",
    "# %%\n",
    "prefix_address(t, rest) = (t == 1) ? (:initial => rest) : (:steps => (t-1) => rest)\n",
    "get_path(trace) = [trace[prefix_address(t, :pose)] for t in 1:(get_args(trace)[1]+1)];\n",
    "\n",
    "@gen (static) function full_model_initial(robot_init, walls, full_settings)\n",
    "    pose ~ start_pose_prior(robot_init, full_settings.motion_settings)\n",
    "    {:sensor} ~ sensor_model(pose, walls, full_settings.sensor_settings)\n",
    "    return pose\n",
    "end\n",
    "\n",
    "@gen (static) function full_model_kernel(t, state, robot_inputs, world_inputs, full_settings)\n",
    "    pose ~ step_model(state, robot_inputs[t], world_inputs, full_settings.motion_settings)\n",
    "    {:sensor} ~ sensor_model(pose, world_inputs.walls, full_settings.sensor_settings)\n",
    "    return pose\n",
    "end\n",
    "full_model_chain = Unfold(full_model_kernel)\n",
    "\n",
    "@gen (static) function full_model(T, robot_init, robot_inputs, world_inputs, full_settings)\n",
    "    initial ~ full_model_initial(robot_init, world_inputs.walls, full_settings)\n",
    "    steps ~ full_model_chain(T, initial, robot_inputs, world_inputs, full_settings)\n",
    "end\n",
    "\n",
    "function sensor_distance(pose, walls, box_size)\n",
    "    d = minimum(distance(pose, seg) for seg in walls)\n",
    "    # Capping to a finite value avoids issues below.\n",
    "    return isinf(d) ? 2. * box_size : d\n",
    "end;\n",
    "\n",
    "sensor_angle(sensor_settings, j) =\n",
    "    sensor_settings.fov * (j - (sensor_settings.sensor_count - 1) / 2) / (sensor_settings.sensor_count - 1)\n",
    "\n",
    "motion_settings = (p_noise = 0.5, hd_noise = 2π / 360)\n",
    "sensor_settings = (fov = 2π*(2/3), sensor_count = 41, box_size = world.box_size, s_noise=0.10)\n",
    "robot_settings = (motion_settings=motion_settings, sensor_settings=sensor_settings)\n",
    "full_model_args = (T, robot_init, robot_inputs, world_inputs, robot_settings)\n",
    "\n",
    "trace = simulate(full_model, full_model_args);\n",
    "selection = select((prefix_address(t, :pose) for t in 1:3)..., (prefix_address(t, :sensor => j) for t in 1:3, j in 1:5)...)\n",
    "get_selected(get_choices(trace), selection)\n",
    "\n",
    "# %% [markdown]\n",
    "# In the math picture, `full_model` corresponds to a distribution $\\text{full}$ over its traces.  Such a trace is identified with of a pair $(z_{0:T}, o_{0:T})$ where $z_{0:T} \\sim \\text{path}(\\ldots)$ and $o_t \\sim \\text{sensor}(z_t, \\ldots)$ for $t=0,\\ldots,T$.  The density of this trace is then\n",
    "# $$\\begin{align*}\n",
    "# P_\\text{full}(z_{0:T}, o_{0:T})\n",
    "# &= P_\\text{path}(z_{0:T}) \\cdot \\prod\\nolimits_{t=0}^T P_\\text{sensor}(o_t) \\\\\n",
    "# &= \\big(P_\\text{start}(z_0)\\ P_\\text{sensor}(o_0)\\big)\n",
    "#   \\cdot \\prod\\nolimits_{t=1}^T \\big(P_\\text{step}(z_t)\\ P_\\text{sensor}(o_t)\\big).\n",
    "# \\end{align*}$$\n",
    "#\n",
    "# By this point, visualization is essential.\n",
    "\n",
    "# %%\n",
    "function get_sensors(trace)\n",
    "    display(trace)\n",
    "    [[trace[prefix_address(t, :sensor => j => :distance)]\n",
    "      for j in 1:get_args(trace)[5].sensor_settings.sensor_count]\n",
    "     for t in 1:(get_args(trace)[1]+1)];\n",
    "end\n",
    "\n",
    "function frames_from_full_trace(world, title, trace; show_clutters=false)\n",
    "    T = get_args(trace)[1]\n",
    "    robot_init = get_args(trace)[2]\n",
    "    robot_inputs = get_args(trace)[3]\n",
    "    poses = get_path(trace)\n",
    "    noiseless_steps = [position(robot_init), [step_along_pose(pose, c.ds) for (pose, c) in zip(poses, robot_inputs)]...]\n",
    "    settings = get_args(trace)[5]\n",
    "    std_devs_radius = 2.5 * settings.motion_settings.p_noise\n",
    "    sensor_readings = get_sensors(trace)\n",
    "    plots = Vector{Plots.Plot}(undef, 2*(T+1))\n",
    "    for t in 1:(T+1)\n",
    "        frame_plot = plot_world(world, title; show_clutters=show_clutters)\n",
    "        plot!(poses[1:t-1]; color=:black, label=\"past poses\")\n",
    "        plot!(make_circle(noiseless_steps[t], std_devs_radius);\n",
    "              color=:red, linecolor=:red, label=\"95% region\", seriestype=:shape, alpha=0.25)\n",
    "        plot!(Pose(trace[prefix_address(t, :pose => :p)], angle(poses[t])); color=:red, label=\"sampled next step\")\n",
    "        plots[2*t-1] = frame_plot\n",
    "        plots[2*t] = frame_from_sensors(\n",
    "            world, title,\n",
    "            poses[1:t], :black, nothing,\n",
    "            poses[t], sensor_readings[t], \"sampled sensors\",\n",
    "            settings.sensor_settings; show_clutters=show_clutters)\n",
    "    end\n",
    "    return plots\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"bonito-fragment\" id=\"0af3af04-2c75-4b50-91fd-807722dc9b58\" data-jscall-id=\"root\">\n",
       "  <div>\n",
       "    <script src=\"http://localhost:9384/assets/4a09a19ef09a5ebd335e9021db888f0a31e7ed3c-Bonito.bundled.js\" type=\"module\"></script>\n",
       "    <style></style>\n",
       "    <div></div>\n",
       "  </div>\n",
       "  <div>\n",
       "    <script type=\"module\">    Bonito.lock_loading(() => {\n",
       "        return Bonito.fetch_binary('http://localhost:9384/assets/df9fb44e741102edb9450d296c121d2d3af3d4de-16728957965049942271.bin').then(msgs=> Bonito.init_session('0af3af04-2c75-4b50-91fd-807722dc9b58', msgs, 'root'));\n",
       "    })\n",
       "</script>\n",
       "    <script type=\"module\">    import('http://localhost:9384/assets/9af6a7ab555f3e745030daedbf654713c0fe1844-Websocket.bundled.js').then(WS => {\n",
       "        WS.setup_connection({proxy_url: 'http://localhost:9384', session_id: '0af3af04-2c75-4b50-91fd-807722dc9b58', compression_enabled: false})\n",
       "    })\n",
       "</script>\n",
       "    <div style=\"width: 100%; height: 100%\" data-jscall-id=\"1\">\n",
       "      <canvas style=\"display: block\" data-jscall-id=\"2\" tabindex=\"0\"></canvas>\n",
       "    </div>\n",
       "  </div>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f = Figure()\n",
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"bonito-fragment\" id=\"06dd92aa-c5a5-4d0e-9415-9fe35525dc57\" data-jscall-id=\"root\">\n",
       "  <div>\n",
       "    <script src=\"http://localhost:9384/assets/4a09a19ef09a5ebd335e9021db888f0a31e7ed3c-Bonito.bundled.js\" type=\"module\"></script>\n",
       "    <style></style>\n",
       "    <div></div>\n",
       "  </div>\n",
       "  <div>\n",
       "    <script type=\"module\">    Bonito.lock_loading(() => {\n",
       "        return Bonito.fetch_binary('http://localhost:9384/assets/f4e4279fe882c6e04ef53a69d62a386e3a150f5b-13180918518734717717.bin').then(msgs=> Bonito.init_session('06dd92aa-c5a5-4d0e-9415-9fe35525dc57', msgs, 'root'));\n",
       "    })\n",
       "</script>\n",
       "    <script type=\"module\">    import('http://localhost:9384/assets/9af6a7ab555f3e745030daedbf654713c0fe1844-Websocket.bundled.js').then(WS => {\n",
       "        WS.setup_connection({proxy_url: 'http://localhost:9384', session_id: '06dd92aa-c5a5-4d0e-9415-9fe35525dc57', compression_enabled: false})\n",
       "    })\n",
       "</script>\n",
       "    <div style=\"width: 100%; height: 100%\" data-jscall-id=\"1\">\n",
       "      <canvas style=\"display: block\" data-jscall-id=\"2\" tabindex=\"0\"></canvas>\n",
       "    </div>\n",
       "  </div>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "InterruptException",
     "evalue": "InterruptException:",
     "output_type": "error",
     "traceback": [
      "InterruptException:\n",
      "\n",
      "Stacktrace:\n",
      "  [1] process_events\n",
      "    @ ./libuv.jl:119 [inlined]\n",
      "  [2] wait()\n",
      "    @ Base ./task.jl:996\n",
      "  [3] yield()\n",
      "    @ Base ./task.jl:875\n",
      "  [4] wait_for(condition::Bonito.var\"#35#36\"{Bonito.Session{Bonito.WebSocketConnection}}; timeout::Int64)\n",
      "    @ Bonito ~/.julia/packages/Bonito/5OnJB/src/util.jl:74\n",
      "  [5] wait_for\n",
      "    @ ~/.julia/packages/Bonito/5OnJB/src/util.jl:71 [inlined]\n",
      "  [6] #wait_for_ready#34\n",
      "    @ ~/.julia/packages/Bonito/5OnJB/src/session.jl:22 [inlined]\n",
      "  [7] get_screen_session(screen::WGLMakie.Screen; timeout::Int64, error::Nothing)\n",
      "    @ WGLMakie ~/.julia/packages/WGLMakie/DMR2f/src/display.jl:208\n",
      "  [8] get_screen_session\n",
      "    @ ~/.julia/packages/WGLMakie/DMR2f/src/display.jl:192 [inlined]\n",
      "  [9] wait_for_display(screen::WGLMakie.Screen)\n",
      "    @ WGLMakie ~/.julia/packages/WGLMakie/DMR2f/src/display.jl:242\n",
      " [10] display(figlike::Figure; backend::Module, inline::Bool, update::Bool, screen_config::@Kwargs{})\n",
      "    @ Makie ~/.julia/packages/Makie/We6MY/src/display.jl:153\n",
      " [11] display(figlike::Figure)\n",
      "    @ Makie ~/.julia/packages/Makie/We6MY/src/display.jl:130\n",
      " [12] #invokelatest#2\n",
      "    @ ./essentials.jl:892 [inlined]\n",
      " [13] invokelatest\n",
      "    @ ./essentials.jl:889 [inlined]\n",
      " [14] (::VSCodeServer.var\"#219#220\"{VSCodeServer.NotebookRunCellArguments, String})()\n",
      "    @ VSCodeServer ~/.vscode/extensions/julialang.language-julia-1.83.2/scripts/packages/VSCodeServer/src/serve_notebook.jl:48\n",
      " [15] withpath(f::VSCodeServer.var\"#219#220\"{VSCodeServer.NotebookRunCellArguments, String}, path::String)\n",
      "    @ VSCodeServer ~/.vscode/extensions/julialang.language-julia-1.83.2/scripts/packages/VSCodeServer/src/repl.jl:276\n",
      " [16] notebook_runcell_request(conn::VSCodeServer.JSONRPC.JSONRPCEndpoint{Base.PipeEndpoint, Base.PipeEndpoint}, params::VSCodeServer.NotebookRunCellArguments)\n",
      "    @ VSCodeServer ~/.vscode/extensions/julialang.language-julia-1.83.2/scripts/packages/VSCodeServer/src/serve_notebook.jl:13\n",
      " [17] dispatch_msg(x::VSCodeServer.JSONRPC.JSONRPCEndpoint{Base.PipeEndpoint, Base.PipeEndpoint}, dispatcher::VSCodeServer.JSONRPC.MsgDispatcher, msg::Dict{String, Any})\n",
      "    @ VSCodeServer.JSONRPC ~/.vscode/extensions/julialang.language-julia-1.83.2/scripts/packages/JSONRPC/src/typed.jl:67\n",
      " [18] serve_notebook(pipename::String, outputchannel_logger::Base.CoreLogging.SimpleLogger; crashreporting_pipename::String)\n",
      "    @ VSCodeServer ~/.vscode/extensions/julialang.language-julia-1.83.2/scripts/packages/VSCodeServer/src/serve_notebook.jl:139\n",
      " [19] top-level scope\n",
      "    @ ~/.vscode/extensions/julialang.language-julia-1.83.2/scripts/notebook/notebook.jl:35"
     ]
    }
   ],
   "source": [
    "f = Figure()\n",
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.10.4",
   "language": "julia",
   "name": "julia-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
